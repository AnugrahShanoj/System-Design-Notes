# ğŸ“˜ System Design â€“ Repo Day 4
## ğŸ“Š System Performance & Scaling Fundamentals

---

# 1ï¸âƒ£ Latency

## ğŸ“Œ Definition

Latency is:

> The time taken to process a single request from start to finish.

It is usually measured in:
- Milliseconds (ms)
- Seconds

---

## ğŸ“Œ What Latency Includes

When a user sends a request, total latency includes:

1. Network travel time (request â†’ server)
2. Server processing time
3. Database query time
4. Response travel time (server â†’ client)

Total of all these = End-to-End Latency

---

## ğŸ“Œ Why Latency Matters

High latency leads to:
- Poor user experience
- User frustration
- Lower engagement

Example:
If Instagram feed loads in 3 seconds, it feels slow.

Lower latency = better user experience.

---

# 2ï¸âƒ£ Throughput

## ğŸ“Œ Definition

Throughput is:

> The number of requests a system can process per second.

Measured in:
- Requests Per Second (RPS)
- Queries Per Second (QPS)

---

## ğŸ“Œ Example

If a server processes:

- 10 requests per second â†’ Throughput = 10 RPS
- 1000 requests per second â†’ Throughput = 1000 RPS

Higher throughput = higher capacity.

---

## ğŸ“Œ Latency vs Throughput

Latency = Time per request  
Throughput = Requests per second  

They are different but related.

Example:
If latency = 100ms (0.1 sec)

Theoretical throughput (single-threaded):
1 / 0.1 = 10 RPS

âš  Important:
Throughput also depends on concurrency and available resources.

---

# 3ï¸âƒ£ QPS (Queries Per Second)

QPS is commonly used for databases.

Definition:

> Number of database queries handled per second.

Example:
If database handles 5000 QPS,
any load beyond that may degrade performance.

---

## ğŸ“Œ Why QPS Matters

During system design interviews, you may be asked:

- Expected traffic?
- Peak QPS?
- Estimated load?

Even rough estimation shows system maturity.

---

# 4ï¸âƒ£ Concurrency vs Parallelism

These terms are often confused.

---

## ğŸŸ¢ Concurrency

Concurrency means:

> Multiple tasks are in progress at the same time.

Example:
A server handling 1000 open connections.
Tasks may share CPU time.

---

## ğŸŸ¢ Parallelism

Parallelism means:

> Multiple tasks are executing at the exact same time.

Requires:
- Multiple CPU cores
- Multiple machines

---

## ğŸ“Œ Analogy

One chef cooking 5 dishes:
- Switching between dishes â†’ Concurrency

Five chefs cooking 5 dishes:
- Cooking simultaneously â†’ Parallelism

---

# 5ï¸âƒ£ Bottlenecks

## ğŸ“Œ Definition

A bottleneck is:

> The component that limits overall system performance.

A system is only as fast as its slowest component.

---

## ğŸ“Œ Common Bottlenecks

- Database queries
- CPU-heavy processing
- Network bandwidth
- Disk I/O
- External API calls
- Application server thread pool

---

## ğŸ“Œ Example Scenario

If:
- Application server handles 10,000 RPS
- Database handles only 1,000 QPS

Database becomes the bottleneck.

---

# 6ï¸âƒ£ Performance Degradation Scenario

Example:

- 1 server
- Each request takes 100ms (0.1 sec)
- Single-threaded processing

Throughput â‰ˆ 10 RPS

If incoming traffic becomes 20 RPS:

- Server can only process 10 RPS
- Extra requests queue up
- Latency increases
- Requests may timeout

This is how overload happens.

---

# ğŸ”’ Memory Lock

Latency â†’ Time per request  
Throughput â†’ Requests per second  
QPS â†’ Database capacity  
Concurrency â†’ Multiple tasks in progress  
Parallelism â†’ Multiple tasks executing simultaneously  
Bottleneck â†’ Performance limiting component  

System performance depends on:
- Latency
- Concurrency
- Resource capacity
- Bottlenecks

